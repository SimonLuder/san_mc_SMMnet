{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from: https://www.kaggle.com/leomauro/smmnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup kaggle api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .kaggle path in user dir if not exists\n",
    "if not os.path.exists(str(Path.home())+\"\\.kaggle\"):\n",
    "    os.makedirs(str(Path.home())+\"\\.kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to www.<span>kaggle.<span>com/**your_username**/account and download a new api-token. \n",
    "After downloading the json file needs to be put into the C:\\Users\\\\**username**\\\\.kaggle directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading smmnet.zip to ./data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/102M [00:00<?, ?B/s]\n",
      "  3%|2         | 3.00M/102M [00:00<00:04, 23.1MB/s]\n",
      "  5%|4         | 5.00M/102M [00:00<00:05, 17.1MB/s]\n",
      "  8%|7         | 8.00M/102M [00:00<00:05, 18.5MB/s]\n",
      " 10%|9         | 10.0M/102M [00:00<00:06, 15.4MB/s]\n",
      " 12%|#1        | 12.0M/102M [00:00<00:05, 16.6MB/s]\n",
      " 15%|#4        | 15.0M/102M [00:00<00:04, 18.3MB/s]\n",
      " 18%|#7        | 18.0M/102M [00:01<00:04, 19.4MB/s]\n",
      " 21%|##        | 21.0M/102M [00:01<00:04, 20.5MB/s]\n",
      " 24%|##3       | 24.0M/102M [00:01<00:03, 21.3MB/s]\n",
      " 27%|##6       | 27.0M/102M [00:01<00:03, 21.6MB/s]\n",
      " 30%|##9       | 30.0M/102M [00:01<00:03, 21.8MB/s]\n",
      " 32%|###2      | 33.0M/102M [00:01<00:03, 22.7MB/s]\n",
      " 35%|###5      | 36.0M/102M [00:01<00:03, 22.6MB/s]\n",
      " 38%|###8      | 39.0M/102M [00:01<00:02, 22.5MB/s]\n",
      " 41%|####1     | 42.0M/102M [00:02<00:02, 22.5MB/s]\n",
      " 44%|####4     | 45.0M/102M [00:02<00:02, 22.5MB/s]\n",
      " 47%|####7     | 48.0M/102M [00:02<00:02, 23.2MB/s]\n",
      " 50%|#####     | 51.0M/102M [00:02<00:02, 22.9MB/s]\n",
      " 53%|#####3    | 54.0M/102M [00:02<00:02, 22.8MB/s]\n",
      " 56%|#####6    | 57.0M/102M [00:02<00:02, 22.6MB/s]\n",
      " 59%|#####9    | 60.0M/102M [00:02<00:01, 23.3MB/s]\n",
      " 62%|######1   | 63.0M/102M [00:03<00:01, 23.0MB/s]\n",
      " 65%|######4   | 66.0M/102M [00:03<00:01, 22.8MB/s]\n",
      " 68%|######7   | 69.0M/102M [00:03<00:01, 22.7MB/s]\n",
      " 71%|#######   | 72.0M/102M [00:03<00:01, 22.6MB/s]\n",
      " 74%|#######3  | 75.0M/102M [00:03<00:01, 22.6MB/s]\n",
      " 77%|#######6  | 78.0M/102M [00:03<00:01, 22.8MB/s]\n",
      " 80%|#######9  | 81.0M/102M [00:03<00:00, 22.9MB/s]\n",
      " 83%|########2 | 84.0M/102M [00:04<00:00, 22.8MB/s]\n",
      " 86%|########5 | 87.0M/102M [00:04<00:00, 23.4MB/s]\n",
      " 89%|########8 | 90.0M/102M [00:04<00:00, 23.1MB/s]\n",
      " 92%|#########1| 93.0M/102M [00:04<00:00, 22.9MB/s]\n",
      " 94%|#########4| 96.0M/102M [00:04<00:00, 22.7MB/s]\n",
      " 97%|#########7| 99.0M/102M [00:04<00:00, 23.4MB/s]\n",
      "100%|##########| 102M/102M [00:04<00:00, 23.0MB/s] \n",
      "100%|##########| 102M/102M [00:04<00:00, 22.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('./data'):\n",
    "    # create data folder\n",
    "    os.makedirs('./data') \n",
    "    \n",
    "    # download csv's\n",
    "    !kaggle datasets download -d \"leomauro/smmnet\" -p \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"clears.csv\",\"course-meta.csv\",\"courses.csv\",\"likes.csv\",\"players.csv\",\"plays.csv\",\"records.csv\"]\n",
    "files_exist = []\n",
    "\n",
    "for file in file_list:\n",
    "    files_exist.append(os.path.isfile(\"./data/\" + file))\n",
    "\n",
    "if not all(files_exist):\n",
    "    with zipfile.ZipFile(\"./data/smmnet.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./data\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import files as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clears = pd.read_csv(\"./data/clears.csv\", delimiter = \"\\t\")\n",
    "course_meta = pd.read_csv(\"./data/course-meta.csv\", delimiter = \"\\t\") # index_col=[\"id\",\"firstClear\"]\n",
    "courses = pd.read_csv(\"./data/courses.csv\", delimiter = \"\\t\")\n",
    "likes = pd.read_csv(\"./data/likes.csv\", delimiter = \"\\t\")\n",
    "players = pd.read_csv(\"./data/players.csv\", delimiter = \"\\t\")\n",
    "plays = pd.read_csv(\"./data/plays.csv\", delimiter = \"\\t\")\n",
    "records = pd.read_csv(\"./data/records.csv\", delimiter = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
