{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kaggle\n",
    "#!pip install missigno\n",
    "#!pip install pandas-profiling\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import regex as re\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data from: https://www.kaggle.com/leomauro/smmnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datenbeschaffung & Aufbereitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup kaggle api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .kaggle path in user dir if not exists\n",
    "if not os.path.exists(str(Path.home())+\"\\.kaggle\"):\n",
    "    os.makedirs(str(Path.home())+\"\\.kaggle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to www.<span>kaggle.<span>com/**your_username**/account and download a new api-token. \n",
    "After downloading the json file needs to be put into the C:\\Users\\\\**username**\\\\.kaggle directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if folder already exists\n",
    "if not os.path.isdir('./data'):\n",
    "    \n",
    "    # if not create data folder\n",
    "    os.makedirs('./data') \n",
    "    \n",
    "    # download csv's\n",
    "    !kaggle datasets download -d \"leomauro/smmnet\" -p \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\"clears.csv\",\"course-meta.csv\",\"courses.csv\",\"likes.csv\",\"players.csv\",\"plays.csv\",\"records.csv\"]\n",
    "files_exist = []\n",
    "\n",
    "# Check if all csv's exist\n",
    "for file in file_list:\n",
    "    files_exist.append(os.path.isfile(\"./data/\" + file))\n",
    "    \n",
    "# if not create csv's\n",
    "if not all(files_exist):\n",
    "    with zipfile.ZipFile(\"./data/smmnet.zip\", 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./data\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import files as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clears = pd.read_csv(\"./data/clears.csv\", delimiter = \"\\t\")\n",
    "course_meta = pd.read_csv(\"./data/course-meta.csv\", delimiter = \"\\t\") # index_col=[\"id\",\"firstClear\"]\n",
    "courses = pd.read_csv(\"./data/courses.csv\", delimiter = \"\\t\")\n",
    "likes = pd.read_csv(\"./data/likes.csv\", delimiter = \"\\t\")\n",
    "players = pd.read_csv(\"./data/players.csv\", delimiter = \"\\t\")\n",
    "plays = pd.read_csv(\"./data/plays.csv\", delimiter = \"\\t\")\n",
    "records = pd.read_csv(\"./data/records.csv\", delimiter = \"\\t\")\n",
    "\n",
    "dfs = {\"clears\":clears, \"course_meta\":course_meta, \"courses\":courses, \"likes\":likes, \"players\":players,\"plays\":plays, \"records\":records}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation\n",
    "In this Kaggle Dataset, we provide over 115 thousand games maps created on Super Mario Maker with over 880 thousand players which performed over 7 millions of interactions on these maps. By interactions, this means that a player can: (1) create a game map; (2) play a map created by other players; if a player completes the challenge of the game map, he/she (3) \"cleared\" the map; also can be the (4) first clear; beat the (5) time record of a map; (6) at any time, the player can \"like\" a game map. Note, this dataset present temporal changes over time for each game map by a period of three months.\n",
    "\n",
    "The data was extracted from supermariomakerbookmark.nintendo.net, the game website. Now it is publicly to everyone play, explore and research. This dataset serves as a good base for learning models, including, but not limited to, Player Modeling (e.g., player experience), Data Mining (e.g., prediction, and find patterns), and Social Network Analysis (e.g., community detection, link prediction, ranking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Check if folder already exists\n",
    "if not os.path.isdir('./df_reports'):\n",
    "    \n",
    "    # if not create data folder\n",
    "    os.makedirs('./df_reports')  \n",
    "    for name, df in dfs.items():\n",
    "        ProfileReport(df, title=f\"Pandas Profiling Report, df = {name}\").to_file(f\"./df_reports/report_{name}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dfs, drop=False, fill=True):\n",
    "    '''Preprocessing function for Super Mario Maker Dataset.\n",
    "    - Changes datatypes where necessary\n",
    "    - Runs multiple asserts to check if quantity/quality of data is correct\n",
    "    - Deals with missing firstClear values\n",
    "    - Corrects \"clears\"-Values where necessary\n",
    "    - Deals with missing values\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    dfs: dict, Dictionary of DataFrames (Super Mario Maker DataFrames from Kaggle)\n",
    "    drop: bool, Removes rows or courses if deemed defect, default False\n",
    "    fill: bool, Fills firstClear Values if clear can be found in clears-df else sets clears to 0, default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dfs : returns dictionary of dataframes\n",
    "    '''\n",
    "\n",
    "    # multiple asserts\n",
    "    assert len(players) >= 880_000, \"Number of players is less than expected\"\n",
    "    assert len(courses) >= 115_000, \"Number of courses is less than expected\"\n",
    "    assert (course_meta.attempts >= course_meta.clears).all(), \"At least one occurance of clears > attempts detected\"\n",
    "    assert len(players) == len(players.id.unique()), \"Player id not unique\"\n",
    "    assert len(courses) == len(courses.id.unique()), \"Course id not unique\"\n",
    "\n",
    "    # add correct dtype to timestamps, and assert values\n",
    "    for name, df in dfs.items():\n",
    "        if \"catch\" in df.columns:\n",
    "            df.catch = pd.to_datetime(df.catch)\n",
    "            assert df.catch.between(\"2017-11-15\",\"2018-04-11\").all(), f\"Detected catch timestamp out of range '2017-11-16' - '2018-04-10' in df {name}\"\n",
    "        elif \"creation\" in df.columns:\n",
    "            df.creation = pd.to_datetime(df.creation)\n",
    "            assert (df.creation <= \"2018-04-10\").all(), f\"Detected creation date more recent than 2018-04-10 in df {name}\"\n",
    "\n",
    "        # test for negative numbers in numeric variables\n",
    "        numerics = ['int64', 'float64']\n",
    "        num_cols = df.select_dtypes(include=numerics).columns\n",
    "        for col in num_cols:\n",
    "            assert (df[col].values >= 0).all(), f\"At least one occurance of negative values detected in df {name}\"\n",
    "\n",
    "        # test if id is in allowed format\n",
    "        r = re.compile(\"[A-Z|0-9]{4}-[A-Z|0-9]{4}-[A-Z|0-9]{4}-[A-Z|0-9]{4}\")\n",
    "        if \"id\" in df.columns and name != \"players\":\n",
    "            assert df.id.str.fullmatch(\"[A-Z|0-9]{4}-[A-Z|0-9]{4}-[A-Z|0-9]{4}-[A-Z|0-9]{4}\").all(), f\"At least one id in wrong format detected in df {name}\"\n",
    "\n",
    "    # sort course_meta and only keep most recent\n",
    "    course_meta_sort = course_meta.sort_values(by=\"catch\",ascending=False)\n",
    "    course_meta_uniq = course_meta_sort.groupby(by=\"id\").first().reset_index()\n",
    "    dfs['course_meta'] = course_meta_uniq\n",
    "    \n",
    "    if fill:\n",
    "        # drop courses with clears > 0 and fistclear == NaN\n",
    "        invalid_courses = course_meta[(course_meta.clears != 0) & (course_meta.firstClear.isna())]\n",
    "        # sort by catch, ascending, get first player for every id and import it into courses_meta\n",
    "        candidate_firstClear = clears[clears.id.isin(list(invalid_courses.id.values))]\n",
    "        candidate_clean = candidate_firstClear.sort_values(by=\"catch\", ascending=True).groupby(by='id').first().reset_index()\n",
    "\n",
    "        def func(row):\n",
    "            if row.id in (candidate_clean.id.values): \n",
    "                return candidate_clean[candidate_clean.id == row.id].player\n",
    "\n",
    "        course_meta['firstClear'] = course_meta.apply(lambda x: func(x), axis=1)\n",
    "\n",
    "        # set clears to 0 for courses that still have no first clear\n",
    "        course_meta.loc[(course_meta.clears != 0) & (course_meta.firstClear.isna()), \"clears\"] = 0\n",
    "        \n",
    "        # check if clears == 0 than firstClear == NaN\n",
    "        assert ((course_meta.clears == 0) & (course_meta.firstClear.isna())).any(), 'Detected courses with clears > 0 and firstClear = NaN'\n",
    "        \n",
    "        # check if sum clears == 0 = firstClear == NaN\n",
    "        assert (len(course_meta.clears == 0) == len(course_meta.firstClear.isna())), 'Missing values in firstClear collumn do not correspond with clears collumn'\n",
    "\n",
    "    # course_meta[course_meta.tag == \"Thumbnail\"] # should thumbnail be possible as a tag?\n",
    "    \n",
    "    # TODO: Change from simple drop to \"database drop\", remove id's and players from all datasets\n",
    "    if drop: \n",
    "        # drop courses with firstClear NaN and clears > 0 (df course_meta)\n",
    "        course_meta.drop(course_meta[(course_meta.clears != 0) & (course_meta.firstClear.isna())].index, inplace=True)\n",
    "        # drop courses with maker NaN (df courses)\n",
    "        courses.drop(courses[courses.maker.isna()].index, inplace=True)\n",
    "        # drop players with no name (df players)\n",
    "        players.drop(players[players.name.isna()].index, inplace=True)\n",
    "        # drop courses where title is NaN\n",
    "        courses.drop(courses[coureses.title.isna()].index, inplace=True)\n",
    "            \n",
    "    return dfs\n",
    "dfs = preprocessing(dfs, drop=True, fill=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(f\"{name}:\")\n",
    "        print(df.isnull().sum())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    msno.matrix(df, figsize=(8,2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in dfs.items():\n",
    "    if \"catch\" in df.columns:\n",
    "        col = \"catch\"\n",
    "    elif \"creation\" in df.columns:\n",
    "        col = \"creation\"\n",
    "    else:\n",
    "        continue\n",
    "    plt.figure(figsize=(8,2))\n",
    "    sns.histplot(df[col]).set_title(f\"Distribution of Timestamps for '{col}' in df {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
